authors:
  - givenNames:
      - Swami
    familyNames:
      - Iyer
    type: Person
    affiliations:
      - type: Organization
  - givenNames:
      - Joshua
    familyNames:
      - Reyes
    type: Person
    affiliations:
      - type: Organization
  - givenNames:
      - Timothy
    familyNames:
      - Killingback
    type: Person
    affiliations:
      - type: Organization
title: >-
  An Application of Evolutionary Game Theory to Social Dilemmas: The Traveler's
  Dilemma and the Minimum Effort Coordination Game
type: Article
content:
  - content:
      - Introduction
    depth: 1
    id: s1
    type: Heading
  - content:
      - >-
        Social dilemmas embody the tension between individual self-interest and
        the common good that is inherent in many important situations in the
        real world. In a social dilemma, individually reasonable behavior
        results in a situation in which all individuals are less well off than
        they could otherwise have been
      - target: '#pone.0093988-Kollock1'
        type: Cite
      - >-
        . Social dilemmas underlie many of the most fundamental and intractable
        problems in the biological and social sciences, such as the evolution of
        cooperation
      - target: '#pone.0093988-Axelrod1'
        type: Cite
      - ' and the efficient use of limited shared resources '
      - target: '#pone.0093988-Hardin1'
        type: Cite
      - >-
        . From a more formal point of view, a social dilemma can be modeled as a
        game in which there exists at least one Hicks inefficient Nash
        equilibrium. It is Hicks inefficient (i.e. socially inefficient) in that
        there is at least one other outcome in which all individuals would be
        better off, and since it is a Nash equilibrium there is no incentive for
        any individual to change their behavior
      - target: '#pone.0093988-Kollock1'
        type: Cite
      - >-
        . Examples of 2-person games that are social dilemmas include: The
        Prisoner's Dilemma
      - target: '#pone.0093988-Axelrod1'
        type: Cite
      - ', '
      - target: '#pone.0093988-Flood1'
        type: Cite
      - ', '
      - target: '#pone.0093988-Hamilton1'
        type: Cite
      - ', the Snowdrift game (also known as the Chicken or Hawk-Dove game) '
      - target: '#pone.0093988-MaynardSmith1'
        type: Cite
      - ', and the Stag-Hunt game (also known as the Assurance game) '
      - target: '#pone.0093988-Skyrms1'
        type: Cite
      - '. Multi-person social dilemmas include, the Public Goods game '
      - target: '#pone.0093988-Isaac1'
        type: Cite
      - ', '
      - target: '#pone.0093988-Fehr1'
        type: Cite
      - ' and the Tragedy of the Commons '
      - target: '#pone.0093988-Hardin1'
        type: Cite
      - >-
        . While the original game theory formalizations of these social dilemmas
        typically involved discrete-strategy games, more recently
        continuous-strategy versions of the Prisoner's Dilemma game
      - target: '#pone.0093988-Killingback1'
        type: Cite
      - ', the Snowdrift game '
      - target: '#pone.0093988-Doebeli1'
        type: Cite
      - ', the Tragedy of the Commons '
      - target: '#pone.0093988-Killingback2'
        type: Cite
      - ' game, and the Public Goods game '
      - target: '#pone.0093988-Killingback3'
        type: Cite
      - ' have been formulated and studied.'
    type: Paragraph
  - content:
      - >-
        One particularly fascinating class of social dilemmas are those for
        which the predictions of game theory appear to be inconsistent with the
        behavior observed when the games are played experimentally
      - target: '#pone.0093988-Holt1'
        type: Cite
      - ". The Traveler's Dilemma (TD) game "
      - target: '#pone.0093988-Basu1'
        type: Cite
      - –
      - target: '#pone.0093988-Goeree1'
        type: Cite
      - ' and the Minimum Effort Coordination (MEC) game '
      - target: '#pone.0093988-Goeree1'
        type: Cite
      - ', '
      - target: '#pone.0093988-VanHuyck1'
        type: Cite
      - ' are two celebrated examples of such games.'
    type: Paragraph
  - content:
      - >-
        These games challenge the notion that the rational solution to a game,
        as embodied in the concept of the Nash equilibrium, accurately describes
        the behavior of humans engaged in these social dilemmas. In the TD game
        there exists a unique, pure strategy, Nash equilibrium that is
        undesirable for all concerned. In contrast to the TD game, in the MEC
        game every pure strategy is a Nash equilibrium, and thus the rational
        solution concept lacks any prescriptive or predictive power.
    type: Paragraph
  - content:
      - >-
        The TD game is conventionally introduced through a story of the
        following form. Two travelers, on their return journey from an exotic
        country, find that their luggage containing identical souvenirs has been
        lost by the airline. The officer in the claims department puts them in
        separate rooms, hands each of them a claims form, and tells them that
        they can claim any integer amount between
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e001'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' and '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e002'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' ('
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e003'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' and '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e004'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' are assumed to be positive integers with '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e005'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - >-
        ). He also informs them that if they both ask for the same amount, they
        will be paid that amount, and if they ask for different amounts, each
        will be reimbursed at the lower value, but with a penalty
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e006'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' deducted from the higher claimant (who is assumed to have lied) and given to the lower claimant (as a reward for being honest). Thus, the TD game is a 2-person game with the discrete strategy set '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e007'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ', and payoff to an '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e008'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - '-claimant against a '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e009'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - '-claimant is defined by '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e010'
        format: ''
        meta:
          inline: false
          linkType: simple
        type: ImageObject
      - (1)
      - >-
        In this context a Nash equilibrium is a pair of claims, such that, if
        each claim is known to the other traveler then neither has reason to
        revise their claim. For
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e011'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - >-
        , there is an incentive for each traveler to undercut any common claim.
        Using backward induction, it is not hard to see that the travelers
        should each claim the amount
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e012'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ', i.e., '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e013'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' is a unique Nash equilibrium for the TD game. Thus, the unique Nash equilibrium of the TD game is the paradoxical outcome in which both travelers claim the lowest possible amount. We note, in particular, that the Nash equilibrium is independent of the reward/punishment parameter '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e014'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - >-
        . However, as intuition would suggest, this is not how individuals
        actually play this game
      - target: '#pone.0093988-Goeree1'
        type: Cite
      - ', '
      - target: '#pone.0093988-Capra1'
        type: Cite
      - –
      - target: '#pone.0093988-Basu3'
        type: Cite
      - '. For instance, '
      - target: '#pone.0093988-Basu3'
        type: Cite
      - ' found the following results when they played the game with 50 subjects (25 pairs). The subjects could make claims between 180 and 300, in two treatments, one with '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e015'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' and another with '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e016'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - '. The results are shown in '
      - content:
          - Figure 1(a)
        target: '#pone-0093988-g001'
        relation: fig
        type: Link
      - . In the high-
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e017'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' treatment, close to 80 percent of all the subjects chose the Nash equilibrium strategy, with an average claim of 201. However, in the low-'
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e018'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' treatment, roughly the same fraction chose the highest possible claim, with an average value of 280. Since the unique Nash equilibrium prediction is independent of the parameter '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e019'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - >-
        , classical game theory is unable to explain the most salient feature of
        these experimental results, namely, the effect of the reward/punishment
        parameter
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e020'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' on average claim levels.'
    type: Paragraph
  - content:
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.g001'
        format: image
        meta:
          inline: false
          linkType: simple
        type: ImageObject
    label: Figure 1
    caption:
      - content:
          - >-
            Results from playing the TD and MEC games with human subjects,
            adapted from
          - target: '#pone.0093988-Goeree1'
            type: Cite
          - .
        depth: 1
        id: s1
        type: Heading
      - content:
          - >-
            (a) TD game: individuals make higher claims when the
            reward/punishment parameter
          - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e021'
            format: ''
            meta:
              inline: true
              linkType: simple
            type: ImageObject
          - ' is low, and make lower claims when '
          - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e022'
            format: ''
            meta:
              inline: true
              linkType: simple
            type: ImageObject
          - ' is high. (b) MEC game: individuals expend more effort when the effort cost '
          - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e023'
            format: ''
            meta:
              inline: true
              linkType: simple
            type: ImageObject
          - ' is low, and less effort when '
          - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e024'
            format: ''
            meta:
              inline: true
              linkType: simple
            type: ImageObject
          - ' is high.'
        type: Paragraph
    type: Figure
  - content:
      - >-
        The MEC game has a somewhat similar flavor to the TD game, in that the
        payoffs are again determined by the minimum of two actions
      - target: '#pone.0093988-Goeree1'
        type: Cite
      - ', '
      - target: '#pone.0093988-VanHuyck1'
        type: Cite
      - ', '
      - target: '#pone.0093988-Goeree2'
        type: Cite
      - '. In this game the players choose integer effort levels between '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e025'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' and '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e026'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' (where '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e027'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' is assumed to be an integer greater than '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e028'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - >-
        ), and a player's payoff is given by the minimum of the two effort
        levels minus the cost of the player's own effort. Therefore, the MEC
        game is a 2-person game with the discrete strategy set
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e029'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ', and payoff to an '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e030'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - '-strategist against a '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e031'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - '-strategist defined by '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e032'
        format: ''
        meta:
          inline: false
          linkType: simple
        type: ImageObject
      - (2)
      - 'where '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e033'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' is a cost parameter. The MEC game suffers from the opposite problem to that of the TD game. Instead of exhibiting a single, deficient, Nash equilibrium, the MEC game exhibits multiple Nash equilibria; it is easy to see that any common effort level is a Nash equilibrium. Moreover, standard refinements of the Nash equilibrium concept do not select a subset of the equilibria. For instance, the Nash equilibria are strict, and thus trembling hand-perfect. Hence, classical game theory provides no obvious criterion to choose among them.'
    type: Paragraph
  - content:
      - >-
        As with the TD game, when the MEC game is actually played with human
        subjects the observed behavior is inconsistent with the results
        predicted by game theory
      - target: '#pone.0093988-Goeree1'
        type: Cite
      - ', '
      - target: '#pone.0093988-VanHuyck1'
        type: Cite
      - '. For example, '
      - target: '#pone.0093988-Goeree1'
        type: Cite
      - ' found the following results in their experiment. The subjects could chose integer effort levels from 110 to 170, in one of two treatments, a low effort cost treatment of '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e034'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' and a high effort cost treatment of '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e035'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - '. The results are shown in '
      - content:
          - Figure 1(b)
        target: '#pone-0093988-g001'
        relation: fig
        type: Link
      - >-
        . In the low effort cost treatment the behavior is concentrated close to
        the highest effort level of 170, while in the high effort cost treatment
        the preponderance of the effort levels are at the lowest possible value.
        These results clearly indicate that the effort levels employed by
        subjects are inversely related to the effort costs, despite the fact
        that any common effort level is a Nash equilibrium.
    type: Paragraph
  - content:
      - >-
        The paradoxical results obtained for the TD and MEC games using
        classical game theory are not resolved by instead using standard
        deterministic evolutionary game theory. Since the unique Nash
        equilibrium
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e036'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' in the TD game is strict it is a globally stable equilibrium point for the replicator dynamics '
      - target: '#pone.0093988-Hofbauer1'
        type: Cite
      - >-
        . Hence, the replicator dynamics of the TD game will always converge to
        the minimum claim level
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e037'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - >-
        . Similarly, in the MEC game every common effort level is a strict Nash
        equilibrium and hence a stable equilibrium point for the replicator
        equations. Thus, the behavior of the replicator dynamics does not select
        any subset of the Nash equilibria. The paradoxical nature of both games
        is, therefore, equally evident when studied using either classical game
        theory or deterministic evolutionary game theory.
    type: Paragraph
  - content:
      - >-
        It is noteworthy that the importance of the TD game and the MEC game are
        rather similar in nature. The TD game is theoretically significant
        because it exposes so clearly an apparently paradoxical aspect of game
        theory: namely the inability of the Nash equilibrium concept to predict
        the actual behavior of individuals interacting in this type of game.
        Moreover, it has been observed in
      - target: '#pone.0093988-Manapat1'
        type: Cite
      - ' that the TD models competitive egg ejection in a species of communally nesting birds, the Greater Ani '
      - target: '#pone.0093988-Riehl1'
        type: Cite
      - ', '
      - target: '#pone.0093988-Riehl2'
        type: Cite
      - >-
        . In this species, if two females share a nest then each female chooses
        a time to change from ejecting eggs from the nest to laying eggs. If
        both select an early time (which corresponds to a large claim), then
        both obtain a large payoff since they can both successfully lay many
        eggs. If, however, one chooses to wait, then she can eject the other
        birds already-laid eggs and obtain an even greater payoff, while at the
        same time inflicting a loss on the other bird
      - target: '#pone.0093988-Manapat1'
        type: Cite
      - '. Thus, this situation has the structure of the TD game.'
    type: Paragraph
  - content:
      - >-
        The MEC game also has both theoretical and practical importance. It is
        theoretically significant because it starkly illustrates the lack of
        prescriptive or predictive power inherent in the notion of Nash
        equilibrium. In addition, it has considerable practical import since
        many interesting and important real-world situations can be modeled by
        MEC games
      - target: '#pone.0093988-Bryant1'
        type: Cite
      - .
    type: Paragraph
  - content:
      - >-
        As an example of how MEC games naturally arise let us consider two
        companies, denoted by A and B, each of which manufacture a critical
        component of a jointly produced product. Let us suppose that company A
        makes widgets, while company B makes grommets. The final product,
        containing both a widget and a grommet, is sold jointly, with the
        revenues being equally split between the two companies. Each company can
        choose the amount of effort to expend in producing its component, with
        higher effort levels resulting in components of higher quality. We shall
        assume that the performance of the final product, and thus also the
        revenues obtained from sales of the product, is limited by whichever of
        the two components has the lower quality. Therefore, the profits
        obtained by a given company from sales of the product may be expressed
        as the minimum of the efforts expended by each company to produce
        widgets or grommets, respectively, minus the cost associated with the
        companies' own effort. Thus, such a situation can be modeled by a MEC
        game.
    type: Paragraph
  - content:
      - >-
        The importance of the TD and MEC games, both theoretically and in
        practice, is clear from the above comments. Therefore, obtaining a
        satisfactory understanding of the dynamics of these games is of
        considerable significance, and it is the purpose of this paper to
        contribute to such an understanding.
    type: Paragraph
  - content:
      - >-
        A number of different theoretical approaches have been investigated as
        possible explanations of the behavior found empirically in the TD and
        MEC games. In one approach, stochastic learning models
      - target: '#pone.0093988-Goeree1'
        type: Cite
      - ', '
      - target: '#pone.0093988-Goeree2'
        type: Cite
      - ', '
      - target: '#pone.0093988-Anderson1'
        type: Cite
      - ' have been proposed to explain the anomalous behavior observed in the TD and MEC games. A quite different approach, using stochastic evolutionary dynamics in finite populations '
      - target: '#pone.0093988-Manapat1'
        type: Cite
      - >-
        , has also been investigated as a means of resolving the paradoxical
        features of the TD game. Other theoretical approaches to explaining the
        behavior of the TD game have been studied in
      - target: '#pone.0093988-Halpern1'
        type: Cite
      - –
      - target: '#pone.0093988-Li1'
        type: Cite
      - >-
        . Other approaches which explore how errors in a game may lead to
        deviations from Nash equilibrium play include
      - target: '#pone.0093988-Camerer1'
        type: Cite
      - –
      - target: '#pone.0093988-Wright1'
        type: Cite
      - .
    type: Paragraph
  - content:
      - >-
        Here we propose an alternative, considerably simpler, theoretical
        framework to explain the evolutionary dynamics of both the TD and MEC
        games, which accounts for the empirically observed behavior. Our method
        applies to a wide class of games that includes both the TD and MEC
        games. We first observe that while the TD and MEC games were originally
        formulated as discrete strategy games it is natural to consider variants
        of these games in which the strategies are continuously variable. In
        this paper we define these continuous-strategy variants of the TD and
        MEC games, which suffer from the same paradoxical behavior as the
        original discrete-strategy games, and it is these continuous-strategy
        games that form the starting point for our approach to understanding the
        evolutionary dynamics of the TD and MEC games.
    type: Paragraph
  - content:
      - >-
        The continuous-strategy forms of the TD and MEC games are two examples
        of a large class of continuous-strategy games which have a discontinuous
        payoff function — other important examples of games from this class
        include the Bertrand Duopoly game
      - target: '#pone.0093988-Tirole1'
        type: Cite
      - ' and the War of Attrition game '
      - target: '#pone.0093988-MaynardSmith1'
        type: Cite
      - >-
        . For such games the role played by errors is potentially important. To
        be precise, let us consider the class of continuous-strategy games with
        payoff function given by
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e038'
        format: ''
        meta:
          inline: false
          linkType: simple
        type: ImageObject
      - (3)
      - 'where '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e039'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' and '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e040'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' are affine functions, and the strategies '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e041'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - >-
        . This class of games includes the continuous-strategy variants of both
        the TD and MEC games. Errors in the observation of an opponents strategy
        or in the implementation of ones own strategy will result in the
        expected payoff to an
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e042'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - '-strategist against a '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e043'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - '-strategist in such a game being given by a function of the form '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e044'
        format: ''
        meta:
          inline: false
          linkType: simple
        type: ImageObject
      - (4)
      - 'where '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e045'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' defines the probability that in an interaction between an '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e046'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - '-strategist and a '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e047'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - '-strategist errors lead to the '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e048'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - '-strategist receiving the payoff '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e049'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ', and '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e050'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' defines the probability that in such an interaction errors result in the '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e051'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - '-strategist receiving the payoff '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e052'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - '. We observe that the probability functions '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e053'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' and '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e054'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' are necessarily complementary in the sense that '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e055'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ', from which it follows that '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e056'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - '. The probability functions '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e057'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' and '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e058'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' are determined by the statistical distribution of errors in the game. Here, for simplicity, we shall assume that the function '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e059'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' is '
      - type: Emphasis
        content:
          - smooth
      - '. Thus, the expected payoff (4) defines a '
      - type: Emphasis
        content:
          - smoothing
      - ' of the original discontinuous payoff function (3). We shall often refer to the function '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e060'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' as the smoothing function. In the limit in which the smoothing function tends to the Heaviside step function the expected payoff (4) approaches the payoff (3).'
    type: Paragraph
  - content:
      - >-
        Since the purpose of this paper is to study the evolutionary behavior of
        the TD and MEC games it is necessary to define a suitable evolutionary
        dynamics for the class of games that we are considering. Since the
        effect of errors in the game is to give an expected payoff which is a
        smooth function, the simplest choice of dynamics is the standard
        deterministic adaptive dynamics
      - target: '#pone.0093988-Metz1'
        type: Cite
      - –
      - target: '#pone.0093988-Geritz2'
        type: Cite
      - ' of the smoothed payoff function. In our approach the effects of errors in the game is encoded in the smoothing function '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e061'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - >-
        . Here we study the evolutionary dynamics of the smoothed versions of
        the TD and MEC game, for an arbitrary smoothing function, and show that
        the results obtained are consistent with those found empirically.
    type: Paragraph
  - content:
      - >-
        The approach to studying the evolutionary dynamics of the TD and MEC
        games that we follow in this paper has some advantages compared to
        stochastic learning models
      - target: '#pone.0093988-Goeree1'
        type: Cite
      - ', '
      - target: '#pone.0093988-Goeree2'
        type: Cite
      - ', '
      - target: '#pone.0093988-Anderson1'
        type: Cite
      - ' or stochastic evolutionary dynamics '
      - target: '#pone.0093988-Manapat1'
        type: Cite
      - >-
        . In the case of stochastic learning models, the evolutionary dynamics
        is governed by the Fokker-Planck equation, which is a nonlinear partial
        differential equation that cannot be solved analytically
      - target: '#pone.0093988-Goeree1'
        type: Cite
      - ', '
      - target: '#pone.0093988-Goeree2'
        type: Cite
      - ', '
      - target: '#pone.0093988-Anderson1'
        type: Cite
      - >-
        . The equilibrium solutions of the evolutionary dynamics are given by
        the solutions to a suitable differential equation. However, it is
        difficult to determine analytically whether or not the equilibrium
        solutions are stable. In fact, the equilibrium solutions to the
        stochastic learning models
      - target: '#pone.0093988-Goeree1'
        type: Cite
      - ', '
      - target: '#pone.0093988-Goeree2'
        type: Cite
      - ', '
      - target: '#pone.0093988-Anderson1'
        type: Cite
      - ' for both the TD and MEC games have not been shown to be stable, and thus, it is unclear whether or not they are attractors of the evolutionary dynamics.'
    type: Paragraph
  - content:
      - 'Stochastic evolutionary dynamics '
      - target: '#pone.0093988-Manapat1'
        type: Cite
      - ' represents an interesting alternative approach to understanding the dynamics of many evolutionary processes. In this case, the evolutionary dynamics is governed by a stochastic process, and the theory is mathematically well-developed. However, there are certain restrictions that apply to the theory. Perhaps the most important is that analytic results can only be obtained in the limit that the selection strength tends to zero. This limit corresponds to the assumption that the contribution to the total payoff that comes from the game interactions is very small. It is not clear that this assumption is realistic when it comes to understanding the behavior of the TD and MEC games. If the assumption of weak selection is not made then it is impossible to obtain analytic results, although numerical simulations can yield results for stronger selection strengths. It is also worth noting that while the stochastic process underlying stochastic evolutionary dynamics is mathematically well-developed, it is rather subtle, and this can present a challenge when applying the method to new problems. In fact, stochastic evolutionary dynamics has not yet been applied to study the MEC game, although we conjecture that such an application will yield results consistent with the behavior observed in the game.'
    type: Paragraph
  - content:
      - >-
        A key advantage of the method that we propose here is that the
        evolutionary dynamics is much easier to study than for either stochastic
        learning models
      - target: '#pone.0093988-Goeree1'
        type: Cite
      - ', '
      - target: '#pone.0093988-Goeree2'
        type: Cite
      - ', '
      - target: '#pone.0093988-Anderson1'
        type: Cite
      - ' or stochastic evolutionary dynamics '
      - target: '#pone.0093988-Manapat1'
        type: Cite
      - >-
        . In particular, it is straightforward to completely determine the
        evolutionary attractors for both the TD and MEC games. A second
        advantage of our method is that it applies directly to a wide variety of
        continuous-strategy games with discontinuous payoff functions, including
        the Bertrand Duopoly model
      - target: '#pone.0093988-Tirole1'
        type: Cite
      - ' and the War of Attrition game '
      - target: '#pone.0093988-MaynardSmith1'
        type: Cite
      - >-
        . In certain cases, which are considered at greater length in the
        Discussion, it can be shown using our methods that complex evolutionary
        dynamics, such as evolutionary branching, can occur in such games.
    type: Paragraph
  - content:
      - >-
        The rest of the paper is organized as follows. In the Models section, we
        define continuous-strategy versions of the TD and MEC games, and also
        introduce the key notion of smoothed versions of these games. In the
        Analysis section, we analyze the evolution of strategies in the smoothed
        games in randomly-interacting populations using adaptive dynamics, and
        in addition formulate an agent-based model of the evolutionary dynamics
        of these games in populations with structures described by an arbitrary
        graph (i.e., network). In the Results section, we present the results of
        simulations using this agent-based model for the evolutionary dynamics
        of the smoothed TD and MEC games, both in well-mixed populations and in
        populations described by complex networks. Finally, in Discussion
        section, we provide a brief discussion of our work and draw some
        conclusions.
    type: Paragraph
  - content:
      - Models
    depth: 1
    id: s2
    type: Heading
  - content:
      - >-
        The strategies in the TD and the MEC games are the claim levels and the
        effort levels, respectively. Typically these games are taken to have a
        discrete set of strategies. However, it is in many ways more natural to
        view the claim levels and effort levels in the two games as being
        continuously variable, and thus to consider variants of these games
        defined for continuous strategies. The continuous forms of the TD and
        MEC games are examples of a broad class of continuous-strategy 2-person
        games with payoff functions given by
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e062'
        format: ''
        meta:
          inline: false
          linkType: simple
        type: ImageObject
      - (5)
      - 'for affine functions '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e063'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' and '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e064'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ', and strategies '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e065'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - '. We may write '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e066'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' more succinctly with the aid of the Heaviside step function '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e067'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e068'
        format: ''
        meta:
          inline: false
          linkType: simple
        type: ImageObject
      - (6)
      - 'as '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e069'
        format: ''
        meta:
          inline: false
          linkType: simple
        type: ImageObject
      - (7)
      - >-
        Games of this form have discontinuous payoff functions. Such a
        discontinuous payoff function is only possible in an idealized world
        free from all errors. In reality, errors in the perception and
        implementation of actions in the game will have the effect of replacing
        the discontinuous payoff function with a smoothed approximation,
        representing the expected payoff. We now define such a variant of the
        game in which the discontinuity in the payoff function is removed by a
        smoothing procedure. To accomplish this we introduce a
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e070'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - '-parameter family of smoothing functions '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e071'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - '. The functions '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e072'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' are assumed to be smooth, non-decreasing functions of '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e073'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ', with '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e074'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ', '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e075'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ', and '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e076'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - '. Furthermore, we assume that '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e077'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' as '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e078'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - '. We will refer to the parameter '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e079'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' as the smoothing parameter.'
    type: Paragraph
  - content:
      - >-
        To obtain the smoothed version of the game defined by (7) we simply
        replace
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e080'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' in the payoff function with its smooth approximation '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e081'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - '. Thus, the payoff function of the smoothed game is given by '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e082'
        format: ''
        meta:
          inline: false
          linkType: simple
        type: ImageObject
      - (8)
      - 'We note that for sufficiently large values of '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e083'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' the smoothed game approximates the original game arbitrarily well.'
    type: Paragraph
  - content:
      - 'A convenient '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e084'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - '-parameter family of smoothing functions is given by '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e085'
        format: ''
        meta:
          inline: false
          linkType: simple
        type: ImageObject
      - (9)
      - >-
        and we shall use this family when explicit smoothing functions are
        required.
    type: Paragraph
  - content:
      - Traveler's Dilemma Game
    depth: 2
    id: s2a
    type: Heading
  - content:
      - >-
        The claims made by individuals in the TD game represent their
        strategies. If
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e086'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' and '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e087'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' denote the strategies used by two individuals playing the continuous version of the game, and if '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e088'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' denotes the reward/punishment parameter (where '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e089'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - '), then the payoff to the '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e090'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - '-strategist is given by '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e091'
        format: ''
        meta:
          inline: false
          linkType: simple
        type: ImageObject
      - (10)
      - >-
        We now define a variant of the TD game defined by (10), in which the
        discontinuity in the payoff function is removed by the smoothing
        procedure described above. To obtain the smoothed TD game we simply
        replace
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e092'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' in the payoff function with its smooth approximation '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e093'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - >-
        . We therefore have that the payoff function for the smoothed TD game is
        given by
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e094'
        format: ''
        meta:
          inline: false
          linkType: simple
        type: ImageObject
      - (11)
      - >-
        We shall assume, without loss of generality, that the strategy space in
        the smoothed TD game is the interval
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e095'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ', and also that the reward/punishment parameter '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e096'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - >-
        . With the payoff function defined by (11), the smoothed TD game
        represents a natural variant of the original TD game.
    type: Paragraph
  - content:
      - Minimum Effort Coordination Game
    depth: 2
    id: s2b
    type: Heading
  - content:
      - >-
        In the MEC game, the effort levels of the individuals represent their
        strategies. In the continuous version of the MEC game, if the strategies
        of two individuals playing the game are
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e097'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' and '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e098'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' (where '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e099'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ') and '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e100'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' is the effort cost, then the payoff '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e101'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' to the '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e102'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - '-strategist is given by '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e103'
        format: ''
        meta:
          inline: false
          linkType: simple
        type: ImageObject
      - (12)
      - 'Using (12) allows us to write the payoff function for the MEC game as '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e104'
        format: ''
        meta:
          inline: false
          linkType: simple
        type: ImageObject
      - (13)
      - >-
        Without loss of generality we can take the strategy space to be the unit
        interval (i.e.
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e105'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - '). Every strategy pair '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e106'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' is a Nash equilibrium in this game. The social dilemma embodied in this continuous-strategy game is clearly the same as for the original discrete MEC game: at any equilibrium both players obtain a payoff of '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e107'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ', thus all equilibria with the sole exception of the strategy pair '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e108'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' are Hicks inefficient.'
    type: Paragraph
  - content:
      - 'To obtain the smoothed MEC game we again replace '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e109'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' in the payoff function (13) with its smooth approximation '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e110'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - '. The payoff function of the smoothed MEC game is therefore given by '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e111'
        format: ''
        meta:
          inline: false
          linkType: simple
        type: ImageObject
      - (14)
      - >-
        With the payoff function defined by (14), the smoothed MEC game
        represents a natural variant of the original MEC game.
    type: Paragraph
  - content:
      - Analysis
    depth: 2
    id: s2c
    type: Heading
  - content:
      - >-
        The dynamics of the smoothed TD and MEC games as formulated in the
        previous section can be analyzed in a well-mixed population using the
        deterministic framework of adaptive dynamics
      - target: '#pone.0093988-Doebeli1'
        type: Cite
      - ', '
      - target: '#pone.0093988-Metz1'
        type: Cite
      - –
      - target: '#pone.0093988-Geritz2'
        type: Cite
      - >-
        . Consider a monomorphic population in which every individual adopts the
        same strategy,
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e112'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - >-
        . It follows from replicator dynamics that the growth rate of a rare
        mutant strategy,
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e113'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ', in the resident '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e114'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' population is '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e115'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ', where '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e116'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' is the payoff to an '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e117'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - '-strategist interacting with a '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e118'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - '-strategist. The quantity '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e119'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' is referred to as the invasion fitness. The evolution of the strategy '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e120'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' is then governed by the selection gradient '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e121'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ', and the adaptive dynamics of '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e122'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' is determined by the differential equation '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e123'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - .
    type: Paragraph
  - content:
      - >-
        Equilibrium points of the adaptive dynamics are called singular
        strategies and are solutions of
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e124'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - '. If no such solutions exist, then the strategy '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e125'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' monotonically increases or decreases under evolution, depending on the sign of '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e126'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - '. If '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e127'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' exists, it is convergent stable and, hence an attractor for the adaptive dynamics, if '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e128'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - '. If this equality is reversed, '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e129'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' is a repeller.'
    type: Paragraph
  - content:
      - >-
        Initially, the population will converge to a convergent stable singular
        point
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e130'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ', but its subsequent evolutionary fate depends on whether '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e131'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' is a maximum or minimum of the invasion fitness '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e132'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - '. If '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e133'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' is a maximum, i.e., if '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e134'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ', then '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e135'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' is an evolutionarily stable strategy (ESS), representing an evolutionary end state in which all individuals adopt strategy '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e136'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - '. If, however, '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e137'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ', then a population of '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e138'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - '-strategists can be invaded by mutant strategies on either side of '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e139'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - >-
        . In this case the population undergoes evolutionary branching and
        splits into two distinct and diverging clusters of strategies.
    type: Paragraph
  - content:
      - >-
        The adaptive dynamics of smoothed games with payoff function defined by
        (8) may be analyzed as follows. The invasion fitness is given by
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e140'
        format: ''
        meta:
          inline: false
          linkType: simple
        type: ImageObject
      - (15)
      - 'Thus, the selection gradient '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e141'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' is given by '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e142'
        format: ''
        meta:
          inline: false
          linkType: simple
        type: ImageObject
      - (16)
      - >-
        The adaptive dynamics of such a game is therefore determined by the
        differential equation
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e143'
        format: ''
        meta:
          inline: false
          linkType: simple
        type: ImageObject
      - (17)
      - 'The existence of singular strategies '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e144'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' in games of this form, and the particular characteristics of any such '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e145'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ', depend on '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e146'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' and '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e147'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ', and thus ultimately on the specific functions '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e148'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' and '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e149'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - . We shall now apply these results to the TD and MEC games.
    type: Paragraph
  - content:
      - Adaptive Dynamics of the Traveler's Dilemma Game
    depth: 2
    id: s2d
    type: Heading
  - content:
      - >-
        Let us first analyze the TD game with the payoff function given by (11).
        Consider a monomorphic population of
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e150'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' strategists, i.e., a population in which every individual claims amount '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e151'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - '. It follows from (2) and (11) that for the TD game '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e152'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' and '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e153'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - '. Thus, the selection gradient '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e154'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' is given by '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e155'
        format: ''
        meta:
          inline: false
          linkType: simple
        type: ImageObject
      - (18)
      - 'and the adaptive dynamics of '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e156'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' is consequently determined by '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e157'
        format: ''
        meta:
          inline: false
          linkType: simple
        type: ImageObject
      - (19)
      - 'Since '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e158'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' does not depend on '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e159'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - >-
        , there are no singular strategies, and thus there is no possibility of
        exotic evolutionary outcomes, such as evolutionary branching. The
        evolutionary dynamics of an initial strategy
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e160'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' is determined by the sign of '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e161'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - '. If '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e162'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' (i.e., if '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e163'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - '), then '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e164'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' will evolve to '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e165'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - '. If on the other hand, '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e166'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' (i.e., '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e167'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ') then '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e168'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' will evolve to '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e169'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - >-
        . Thus, this adaptive dynamics analysis implies that the players of the
        smoothed TD game will evolve to make low claims if
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e170'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ', and, conversely, evolve to make high claims if '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e171'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - '. We note that for the '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e172'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - >-
        -parameter family of smoothing functions defined by (9), this criterion
        takes the following form: claims will evolve to low levels if
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e173'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ', and evolve to high levels if '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e174'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - .
    type: Paragraph
  - content:
      - Adaptive Dynamics of the Minimum Effort Coordination Game
    depth: 2
    id: s2e
    type: Heading
  - content:
      - >-
        We next turn to the MEC game where the payoff function is given by (14).
        Consider a monomorphic population of
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e175'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' strategists, i.e., a population in which every individual puts in '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e176'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' amount of effort. It follows from (2) and (13) that for the MEC game '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e177'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' and '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e178'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - '. Thus, the selection gradient '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e179'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' is given by '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e180'
        format: ''
        meta:
          inline: false
          linkType: simple
        type: ImageObject
      - (20)
      - 'and the adaptive dynamics of '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e181'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' is therefore determined by '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e182'
        format: ''
        meta:
          inline: false
          linkType: simple
        type: ImageObject
      - (21)
      - 'Again, since '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e183'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' does not depend on '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e184'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - >-
        , there are no singular strategies. Also, rather remarkably, the
        adaptive dynamics of
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e185'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' is independent of the smoothing function '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e186'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - '. The evolution of an initial strategy '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e187'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' is once again determined by the sign of '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e188'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - '. If '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e189'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' (i.e., if '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e190'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ') then '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e191'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' will evolve to '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e192'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ', and if '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e193'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' (i.e., if '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e194'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ') then '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e195'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' will evolve to '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e196'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - >-
        . Therefore, this adaptive dynamics analysis implies that the players'
        strategies in the smoothed MEC game will evolve to low efforts if the
        effort cost
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e197'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' is greater than '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e198'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ', and to high efforts if '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e199'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - >-
        . Since the adaptive dynamics of the smoothed MEC game is independent of
        the smoothing function, these results hold for any smoothing of the
        game.
    type: Paragraph
  - content:
      - >-
        We note that the behavior predicted by adaptive dynamics for the
        smoothed TD and MEC games is in accord with that observed for the TD and
        MEC games in experiments.
    type: Paragraph
  - content:
      - Agent-Based Simulations
    depth: 2
    id: s2f
    type: Heading
  - content:
      - >-
        In this section, we define a stochastic agent-based model which allows
        the evolutionary dynamics of the TD and MEC games to be studied both for
        random interactions between members of the population and for more
        complex interaction patterns in the population. The evolutionary
        dynamics of simple social dilemmas, such as the Prisoner's Dilemma and
        the Snowdrift game, have been well-studied for populations with a
        variety of complex interaction patterns
      - target: '#pone.0093988-Nowak1'
        type: Cite
      - –
      - target: '#pone.0093988-Szabo1'
        type: Cite
      - .
    type: Paragraph
  - content:
      - 'Consider a population consisting of '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e200'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' individuals, labeled '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e201'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - >-
        . Since we wish to allow the possibility of complex population
        structures, we identify the population with the set of vertices in a
        graph
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e202'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - '. The structure of '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e203'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' determines which individuals in the population can interact. Strictly speaking, two graphs are required to specify the evolutionary dynamics: an interaction graph, '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e204'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - >-
        , specifies that two individuals in the population can interact by
        playing the game only if they are adjacent in
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e205'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ', and an updating graph, '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e206'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - >-
        , specifies that an individual in the population can update its strategy
        by comparing its state to the states only of those individuals adjacent
        to it in
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e207'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - >-
        . Here, for simplicity, we shall assume that the interaction and
        updating graphs are the same i.e.,
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e208'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - '. Given an individual '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e209'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ', the set of neighbors of '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e210'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' (i.e., the set of individuals adjacent to '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e211'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' in '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e212'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ') will be denoted by '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e213'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - .
    type: Paragraph
  - content:
      - 'The agent-based model is defined as a stochastic process on '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e214'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - >-
        . Let us fix either the TD or the MEC game as the game under
        consideration. We begin with a monomorphic population, i.e., each
        individual in the population starts out with the same initial strategy
        randomly picked from a uniform distribution. At each time step
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e215'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - >-
        , we carry out a round of asynchronous interactions followed by a round
        of asynchronous updates. Each of these rounds involves sampling the
        population with replacement.
    type: Paragraph
  - content:
      - 'During an interaction step, we randomly pick an individual '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e216'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' and an individual '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e217'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ', and let the two individuals play the game against each other. If '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e218'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' and '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e219'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' denote the strategies of '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e220'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' and '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e221'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ', respectively, then the payoff '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e222'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' received by the focal individual '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e223'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' is given by either '
      - content:
          - equation (11
        target: '#pone.0093988.e094'
        relation: disp-formula
        type: Link
      - >-
        ) or (14), depending on the game under consideration. This procedure is
        repeated
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e224'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' times.'
    type: Paragraph
  - content:
      - 'During an update step, we randomly pick an individual '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e225'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' and an individual '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e226'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - '. If '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e227'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' and '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e228'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' denote the payoffs of '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e229'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' and '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e230'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ', respectively, then with probability '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e231'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' given by '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e232'
        format: ''
        meta:
          inline: false
          linkType: simple
        type: ImageObject
      - (22)
      - 'the focal individual '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e233'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' will inherit '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e234'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - >-
        's strategy. This update rule is often referred to as the Fermi rule.
        The parameter
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e235'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - " is the “selection strength'' of the update rule. The update procedure is repeated "
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e236'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' times.'
    type: Paragraph
  - content:
      - >-
        Mutations are incorporated in the update procedure in the following way:
        when according to the update rule (22)
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e237'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - "'s strategy would be replaced by "
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e238'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - "'s, then with probability "
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e239'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ', '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e240'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - >-
        's strategy is instead replaced by a strategy picked randomly from a
        normal distribution with mean equal to
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e241'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - "'s strategy and standard deviation "
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e242'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - '. Carrying out '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e243'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' interaction steps followed by '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e244'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' update steps constitutes a single generation of the evolutionary dynamics.'
    type: Paragraph
  - content:
      - >-
        We note here that the results of our agent-based simulations (described
        in detail in the next section) are robust to variations in the update
        rule. For example, in addition to employing the Fermi update rule (22),
        we have also simulated the agent-based model using the
      - type: Emphasis
        content:
          - replicator
      - ' update rule, in which the probability '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e245'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' that the focal individual '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e246'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' inherits individual '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e247'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - "'s strategy (with "
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e248'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ') is given by '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e249'
        format: ''
        meta:
          inline: false
          linkType: simple
        type: ImageObject
      - (23)
      - 'where '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e250'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ', and '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e251'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - >-
        . We find that the evolutionary dynamics of the smoothed TD and MEC
        games is the same irrespective of which of these update rules we employ.
        The results presented in the next section on the evolutionary dynamics
        of the TD and MEC games arise from simulations using the Fermi update
        rule (22).
    type: Paragraph
  - content:
      - Results
    depth: 1
    id: s3
    type: Heading
  - content:
      - >-
        In this section we present the results of agent-based simulations for
        the TD and MEC games. For both the smoothed TD and MEC games the
        agent-based model described in the previous section was simulated (using
        the Fermi update rule (22) and the smoothing function (9)) on the
        following graphs (see, for example,
      - target: '#pone.0093988-Watts1'
        type: Cite
      - –
      - target: '#pone.0093988-Newman1'
        type: Cite
      - >-
        .): a complete graph (which models a randomly-interacting population); a
        random regular graph of degree 10; a scale-free graph with mean degree
        10; and two-dimensional lattice graphs with 4 and 8 neighbors,
        respectively, and periodic boundary conditions. The games were simulated
        for 20000 generations. The parameter values used for the simulations
        were: population size,
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e252'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' for the lattice graphs and '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e253'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' for the other graphs; mutation rate, '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e254'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - '; standard deviation for mutations, '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e255'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - '; smoothing parameter, '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e256'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' for the TD game and '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e257'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' for the MEC game; and selection strength, '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e258'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - .
    type: Paragraph
  - content:
      - Traveler's Dilemma Game
    depth: 2
    id: s3a
    type: Heading
  - content:
      - content:
          - Figure 2
        target: '#pone-0093988-g002'
        relation: fig
        type: Link
      - ' shows the variation of the average claims '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e259'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' made by individuals over the last '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e260'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' of '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e261'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' generations with the reward/punishment parameter '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e262'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ', for different values of the smoothing parameter '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e263'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - >-
        , on the following graphs: (a) a complete graph, (c) a random regular
        graph, (d) a scale-free graph, (e) a 2D lattice graph with 4 neighbors,
        and (f) a 2D lattice graph with 8 neighbors. The
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e264'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' value was varied from 0 to 1 in steps of '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e265'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ', and each data point was obtained from an average of '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e266'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' runs of the model. It is apparent from these results that, for each value of '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e267'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ', the claims are high when '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e268'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' and low when '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e269'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - >-
        , exactly as predicted by the adaptive dynamics analysis. This behavior
        is in good qualitative agreement with the results obtained for the TD
        game in experiments. Furthermore, these simulation results suggest that
        network structure has very little effect on the evolutionary dynamics of
        the game.
    type: Paragraph
  - content:
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.g002'
        format: image
        meta:
          inline: false
          linkType: simple
        type: ImageObject
    label: Figure 2
    caption:
      - content:
          - Results from simulating the TD game.
        depth: 2
        id: s3a
        type: Heading
      - content:
          - '(a)(c)(d)(e)(f) Average claims '
          - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e270'
            format: ''
            meta:
              inline: true
              linkType: simple
            type: ImageObject
          - ' in the smoothed TD game over the last '
          - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e271'
            format: ''
            meta:
              inline: true
              linkType: simple
            type: ImageObject
          - ' of '
          - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e272'
            format: ''
            meta:
              inline: true
              linkType: simple
            type: ImageObject
          - ' generations versus the reward/punishment parameter '
          - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e273'
            format: ''
            meta:
              inline: true
              linkType: simple
            type: ImageObject
          - ' for different values of the smoothing parameter '
          - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e274'
            format: ''
            meta:
              inline: true
              linkType: simple
            type: ImageObject
          - >-
            , on a complete graph (a), a random regular graph with degree 10
            (c), a scale-free graph with mean degree 10 (d), 2D lattice graph
            with 4 neighbors (e), and 2D lattice graph with 8 neighbors (f).
            Parameter values:
          - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e275'
            format: ''
            meta:
              inline: true
              linkType: simple
            type: ImageObject
          - ' for lattice networks and '
          - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e276'
            format: ''
            meta:
              inline: true
              linkType: simple
            type: ImageObject
          - ' for other networks, '
          - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e277'
            format: ''
            meta:
              inline: true
              linkType: simple
            type: ImageObject
          - ', and '
          - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e278'
            format: ''
            meta:
              inline: true
              linkType: simple
            type: ImageObject
          - '. (b) Number of individuals versus their claims '
          - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e279'
            format: ''
            meta:
              inline: true
              linkType: simple
            type: ImageObject
          - ', when '
          - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e280'
            format: ''
            meta:
              inline: true
              linkType: simple
            type: ImageObject
          - ' and '
          - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e281'
            format: ''
            meta:
              inline: true
              linkType: simple
            type: ImageObject
          - ', on a complete graph with parameter values: '
          - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e282'
            format: ''
            meta:
              inline: true
              linkType: simple
            type: ImageObject
          - ', and '
          - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e283'
            format: ''
            meta:
              inline: true
              linkType: simple
            type: ImageObject
          - .
        type: Paragraph
    type: Figure
  - content:
      - content:
          - Figure 2(b)
        target: '#pone-0093988-g002'
        relation: fig
        type: Link
      - ' shows the variation in the number of individuals with the claims '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e284'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' they make, when '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e285'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' and '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e286'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ', on a complete graph, with '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e287'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - '. Individuals make higher claims when '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e288'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ', as indicated by the blue bars, and make lower claims when '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e289'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - >-
        , as indicated by the green bars. This result is in good agreement with
        the empirical results shown in
      - content:
          - Figure 1(a)
        target: '#pone-0093988-g001'
        relation: fig
        type: Link
      - .
    type: Paragraph
  - content:
      - >-
        We have also simulated the game using the discontinuous form of the
        payoff function (10), and the results are shown in blue (labeled
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e290'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ') in panels (a), (c), (d), (e), and (f) of '
      - content:
          - Figure 2
        target: '#pone-0093988-g002'
        relation: fig
        type: Link
      - '. In this case, the claims are consistently low for all values of '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e291'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - >-
        . This result, which is consistent with the prediction of the adaptive
        dynamics analysis of the smoothed TD game in the limit
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e292'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - >-
        , is in agreement with the prediction of classical game theory for the
        original TD game. Thus, for the TD game studied here, the smoothing of
        the payoff function is necessary to explain the empirically observed
        behavior.
    type: Paragraph
  - content:
      - Minimum Effort Coordination Game
    depth: 2
    id: s3b
    type: Heading
  - content:
      - content:
          - Figure 3
        target: '#pone-0093988-g003'
        relation: fig
        type: Link
      - ' shows the variation of the average effort levels '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e293'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' of the individuals over the last '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e294'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' of '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e295'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' generations with the effort cost parameter '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e296'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ', for various values of the smoothing parameter '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e297'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - >-
        , on the following graphs: (a) a complete graph, (c) a random regular
        graph, (d) a scale-free graph, (e) a 2D lattice graph with 4 neighbors,
        and (f) a 2D lattice graph with 8 neighbors. The
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e298'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' value was varied from 0 to 1 in steps of '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e299'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ', and each data point was obtained from an average over '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e300'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' runs of the model. It is clear from these results that, for each value of '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e301'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ', the effort levels are high when '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e302'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' and low when '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e303'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - >-
        , exactly as suggested by the adaptive dynamics analysis. These results
        are in good qualitative agreement with the empirically observed behavior
        in experiments. The results of these agent-based simulations clearly
        show the independence of the evolutionary dynamics of the smoothed MEC
        game on the smoothing function (i.e., the independence on
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e304'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - >-
        ), which is predicted by the adaptive dynamics analysis. These results
        also suggest that the effect of network structure on the dynamics of the
        smoothed MEC game is negligible.
    type: Paragraph
  - content:
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.g003'
        format: image
        meta:
          inline: false
          linkType: simple
        type: ImageObject
    label: Figure 3
    caption:
      - content:
          - Results from simulating the MEC game.
        depth: 2
        id: s3b
        type: Heading
      - content:
          - '(a)(c)(d)(e)(f) Average effort levels '
          - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e305'
            format: ''
            meta:
              inline: true
              linkType: simple
            type: ImageObject
          - ' in the smoothed MEC game over the last '
          - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e306'
            format: ''
            meta:
              inline: true
              linkType: simple
            type: ImageObject
          - ' of '
          - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e307'
            format: ''
            meta:
              inline: true
              linkType: simple
            type: ImageObject
          - ' generations versus the effort cost parameter '
          - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e308'
            format: ''
            meta:
              inline: true
              linkType: simple
            type: ImageObject
          - ' for different values of the smoothing parameter '
          - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e309'
            format: ''
            meta:
              inline: true
              linkType: simple
            type: ImageObject
          - >-
            , on a complete graph (a), a random regular graph with degree 10
            (c), a scale-free graph with mean degree 10 (d), 2D lattice graph
            with 4 neighbors (e), and 2D lattice graph with 8 neighbors (f).
            Parameter values:
          - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e310'
            format: ''
            meta:
              inline: true
              linkType: simple
            type: ImageObject
          - ' for lattice graphs and '
          - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e311'
            format: ''
            meta:
              inline: true
              linkType: simple
            type: ImageObject
          - ' for other graphs, '
          - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e312'
            format: ''
            meta:
              inline: true
              linkType: simple
            type: ImageObject
          - ', and '
          - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e313'
            format: ''
            meta:
              inline: true
              linkType: simple
            type: ImageObject
          - '. (b) Number of individuals versus their effort levels '
          - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e314'
            format: ''
            meta:
              inline: true
              linkType: simple
            type: ImageObject
          - ', when '
          - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e315'
            format: ''
            meta:
              inline: true
              linkType: simple
            type: ImageObject
          - ' and '
          - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e316'
            format: ''
            meta:
              inline: true
              linkType: simple
            type: ImageObject
          - ', on a complete graph with parameter values: '
          - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e317'
            format: ''
            meta:
              inline: true
              linkType: simple
            type: ImageObject
          - ', and '
          - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e318'
            format: ''
            meta:
              inline: true
              linkType: simple
            type: ImageObject
          - .
        type: Paragraph
    type: Figure
  - content:
      - content:
          - Figure 3(b)
        target: '#pone-0093988-g003'
        relation: fig
        type: Link
      - ' shows the variation in the number of individuals with their effort levels '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e319'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ', when '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e320'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' and '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e321'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ', on a complete network, with '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e322'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - '. Individuals expend more effort when '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e323'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ', as indicated by the blue bars, and expend lower effort when '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e324'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - >-
        , as indicated by the green bars. This result is in good agreement with
        the empirical results shown in
      - content:
          - Figure 1(b)
        target: '#pone-0093988-g001'
        relation: fig
        type: Link
      - .
    type: Paragraph
  - content:
      - >-
        We also simulated the model using the discontinuous form of the payoff
        function (13), and the result is shown in blue (
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e325'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ') in plots (a), (c), (d), (e), and (f) of '
      - content:
          - Figure 3
        target: '#pone-0093988-g003'
        relation: fig
        type: Link
      - >-
        . In this case, there is still a transition from high to low effort
        levels as the effort cost increases, however, it is typically not as
        sharp as for the smoothed game (with any value of
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e326'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - >-
        ). An intriguing exception to this pattern is found in the case of
        two-dimensional lattice graphs, for which the evolutionary dynamics of
        the game with discontinuous payoff function is essentially identical to
        that of the smoothed game (for any value of the smoothing parameter). We
        tentatively conjecture that the feature of lattice graphs which is
        responsible for this effect is that they possess non-trivial clustering
        coefficients (
      - target: '#pone.0093988-Watts1'
        type: Cite
      - –
      - target: '#pone.0093988-Newman1'
        type: Cite
      - >-
        ) — in contrast to the other graphs we have considered, which have zero
        clustering. The potential effect of the clustering coefficient on the
        evolutionary dynamics of the MEC game defined on graphs appears to be an
        interesting topic for future research.
    type: Paragraph
  - content:
      - Discussion
    depth: 1
    id: s4
    type: Heading
  - content:
      - >-
        In this work we have proposed simple and natural continuous-strategy
        versions of the classical discrete-strategy TD and MEC games. We have
        modeled these games as continuous games with smooth payoff functions,
        where the smoothing accounts for the effects of errors in the perception
        and/or implementation of individuals actions. The smoothed TD and MEC
        games can be effectively analyzed using adaptive dynamics, which shows
        that the predicted evolutionary dynamics of these games is in accord
        with the behavior observed in empirical studies of the TD and MEC games.
        In addition, we have studied the evolutionary dynamics of the smoothed
        TD and MEC games using agent-based simulations. These simulations have
        been performed both for populations of randomly-interacting agents and
        for populations with more complex interaction patterns, represented by
        graphs of varying topologies. These simulation results are in agreement
        both with the analytical adaptive dynamics results, and also with the
        experimentally observed behavior.
    type: Paragraph
  - content:
      - >-
        For the smoothed TD game, we find both from the adaptive dynamics
        analysis and from the agent-based simulations, that claims vary with the
        reward/punishment parameter
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e327'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' in a fashion that is in excellent agreement with the empirically observed behavior: low values of '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e328'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' result in high claims and high values of '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e329'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' result in low claims. We recover the classical game theory result that claims in the TD game with discontinuous payoff remain low for all values of '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e330'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' by considering the limit in which the smoothing parameter '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e331'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - >-
        . Different interaction patterns among the individuals playing the
        smoothed TD game, as represented by studying the game on graphs of
        different topologies, appears to have little effect on the evolutionary
        dynamics of the game.
    type: Paragraph
  - content:
      - >-
        We find similarly satisfactory results for the smoothed MEC game. The
        analysis, both analytical and through simulations, again yields results
        in good agreement with experiment: high effort levels are found for low
        effort cost
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e332'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' and low effort levels occur for high effort cost. We again find that when the smoothed MEC game is formulated on graphs of differing topology the topological type has no significant effect on the evolutionary dynamics of the game.'
    type: Paragraph
  - content:
      - >-
        The methods introduced in this paper are quite general and can be
        applied to a wide variety of continuous-strategy games with
        discontinuous payoff functions. Important examples of other games that
        can be fruitfully studied using these methods include the Bertrand
        Duopoly model
      - target: '#pone.0093988-Tirole1'
        type: Cite
      - ' and the War of Attrition game '
      - target: '#pone.0093988-MaynardSmith1'
        type: Cite
      - >-
        . Here we will only briefly discuss the application of our methods to
        these two games — detailed accounts will be given elsewhere.
    type: Paragraph
  - content:
      - 'In the classical Bertrand Duopoly (BD) model '
      - target: '#pone.0093988-Tirole1'
        type: Cite
      - ' one considers the interactions between two firms that produce a homogeneous product. The strategy of each firm is the unit price that they set for their product. It is assumed that customers will buy a quantity '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e333'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' (where '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e334'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' is the demand function) from the firm with the lower price '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e335'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - >-
        , and will buy nothing from the firm with the higher price. If both
        firms set the same price then it is assumed that demand is split equally
        between them. It is also assumed that both firms have the same marginal
        cost
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e336'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - >-
        . Thus, the payoff obtained by one firm in its interaction with the
        other is a discontinuous function of the difference between the prices
        set by the two firms. This discontinuous payoff function can be smoothed
        in exactly the manner described in this paper to yield a smoothed game.
        In this case the smoothing function represents the probability that
        customers buy the product from the firm with the lower price as opposed
        to the firm with the higher price. In the limit that this probability
        tends to one, the smoothed game approaches the classical game.
    type: Paragraph
  - content:
      - >-
        The smoothed BD model can be analyzed using adaptive dynamics just as we
        have done here for the TD and MEC games. It may be shown for an
        arbitrary smoothing, that given a linear demand function
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e337'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' there exists a unique singular strategy '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e338'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' (in the domain of interest), that is strictly greater than the marginal cost '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e339'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - '. Furthermore, it may also be shown that the singular strategy '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e340'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' is always both convergent stable and an ESS. Thus, the evolutionary dynamics of the smoothed BD game results in the prices set by both firms converging to the level '
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e341'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - >-
        , which is strictly greater than the marginal cost. At the evolutionary
        equilibrium
      - contentUrl: 'info:doi/10.1371/journal.pone.0093988.e342'
        format: ''
        meta:
          inline: true
          linkType: simple
        type: ImageObject
      - ' both firms obtain a positive payoff. Thus, the introduction of the smoothed BD model effectively resolves the Bertrand Paradox that occurs in the classical model. Moreover, our method extends to the case of an arbitrary number of firms and sheds light on the results obtained in '
      - target: '#pone.0093988-Dufwenberg1'
        type: Cite
      - .
    type: Paragraph
  - content:
      - >-
        The second example that will be mentioned here is the War of Attrition
        (WoA) game
      - target: '#pone.0093988-MaynardSmith1'
        type: Cite
      - >-
        . The classical WoA game is concerned with two individuals who are
        contesting a resource. In this game each individual chooses a ''display
        investment,'' which is a continuous variable representing the
        individual's strategy. The payoff in the classical game is a
        discontinuous function of the difference in the display investments
        since it is assumed that the individual with the higher investment
        obtains the resource, while the lower investor does not, and both pay a
        cost that is a function of the lower investment value.
    type: Paragraph
  - content:
      - >-
        This game can be smoothed and studied using adaptive dynamics as we have
        done in this paper for the TD and MEC games. It may be shown that the
        evolutionary dynamics depends critically on the form of the cost
        function. For a linear cost function, there exists a singular strategy
        that is always both convergent stable and an ESS. However, for quadratic
        cost functions, there exist singular strategies that are evolutionary
        branching points. Thus, in the latter case, complex and surprising
        evolutionary dynamics can occur.
    type: Paragraph
  - content:
      - >-
        In conclusion, therefore, we have introduced a new method of formulating
        and analyzing the evolutionary dynamics of a wide class of games, which
        include the continuous-strategy variants of the TD and MEC games. We
        have studied the case of the smoothed TD and MEC games in detail and
        shown that our method provides a means of resolving the paradoxical
        behavior associated with the original form of the games.
    type: Paragraph
references:
  - authors:
      - givenNames:
          - P
        familyNames:
          - Kollock
        type: Person
    title: 'Social dilemmas: The anatomy of cooperation'
    type: Article
    datePublished: '1998'
    isPartOf:
      pageStart: 183
      pageEnd: 214
      title: Annual Review of Sociology
      volumeNumber: 24
      type: PublicationVolume
    id: pone.0093988-Kollock1
  - authors: []
    title: ''
    type: Article
    id: pone.0093988-Axelrod1
  - authors:
      - givenNames:
          - G
        familyNames:
          - Hardin
        type: Person
    title: The tragedy of the commons
    type: Article
    datePublished: '1968'
    isPartOf:
      pageStart: 1243
      pageEnd: 1248
      title: Science
      volumeNumber: 162
      type: PublicationVolume
    id: pone.0093988-Hardin1
  - authors:
      - givenNames:
          - MM
        familyNames:
          - Flood
        type: Person
    title: Some experimental games
    type: Article
    datePublished: '1958'
    isPartOf:
      pageStart: 5
      pageEnd: 26
      title: Management Science
      volumeNumber: 5
      type: PublicationVolume
    id: pone.0093988-Flood1
  - authors:
      - givenNames:
          - W
        familyNames:
          - Hamilton
        type: Person
      - givenNames:
          - R
        familyNames:
          - Axelrod
        type: Person
    title: The evolution of cooperation
    type: Article
    datePublished: '1981'
    isPartOf:
      pageStart: 1390
      pageEnd: 1396
      title: Science
      volumeNumber: 211
      type: PublicationVolume
    id: pone.0093988-Hamilton1
  - authors: []
    title: ''
    type: Article
    id: pone.0093988-MaynardSmith1
  - authors: []
    title: ''
    type: Article
    id: pone.0093988-Skyrms1
  - authors:
      - givenNames:
          - R
        familyNames:
          - Isaac
        type: Person
      - givenNames:
          - J
        familyNames:
          - Walker
        type: Person
    title: >-
      Group size effects in public goods provision: The voluntary contributions
      mechanism
    type: Article
    datePublished: '1988'
    isPartOf:
      pageStart: 179
      pageEnd: 199
      title: The Quarterly Journal of Economics
      volumeNumber: 103
      type: PublicationVolume
    id: pone.0093988-Isaac1
  - authors:
      - givenNames:
          - E
        familyNames:
          - Fehr
        type: Person
      - givenNames:
          - S
        familyNames:
          - Gachter
        type: Person
    title: Altruistic punishment in humans
    type: Article
    datePublished: '2002'
    isPartOf:
      pageStart: 137
      pageEnd: 140
      title: Nature
      volumeNumber: 415
      type: PublicationVolume
    id: pone.0093988-Fehr1
  - authors:
      - givenNames:
          - T
        familyNames:
          - Killingback
        type: Person
      - givenNames:
          - M
        familyNames:
          - Doebeli
        type: Person
      - givenNames:
          - 'N'
        familyNames:
          - Knowlton
        type: Person
    title: >-
      Variable investment, the continuous prisoner's dilemma, and the origin of
      cooperation
    type: Article
    datePublished: '1999'
    isPartOf:
      pageStart: 1723
      pageEnd: 1728
      title: 'Proceedings of the Royal Society of London Series B: Biological Sciences'
      volumeNumber: 266
      type: PublicationVolume
    id: pone.0093988-Killingback1
  - authors:
      - givenNames:
          - M
        familyNames:
          - Doebeli
        type: Person
      - givenNames:
          - C
        familyNames:
          - Hauert
        type: Person
      - givenNames:
          - T
        familyNames:
          - Killingback
        type: Person
    title: The evolutionary origin of cooperators and defectors
    type: Article
    datePublished: '2004'
    isPartOf:
      pageStart: 859
      pageEnd: 862
      title: Science
      volumeNumber: 306
      type: PublicationVolume
    id: pone.0093988-Doebeli1
  - authors:
      - givenNames:
          - T
        familyNames:
          - Killingback
        type: Person
      - givenNames:
          - M
        familyNames:
          - Doebeli
        type: Person
      - givenNames:
          - C
        familyNames:
          - Hauert
        type: Person
    title: Cooperation and defection in the tragedy of the commons
    type: Article
    datePublished: '2010'
    isPartOf:
      pageStart: 3
      pageEnd: 6
      title: Biological Theory
      volumeNumber: 5
      type: PublicationVolume
    id: pone.0093988-Killingback2
  - authors:
      - givenNames:
          - T
        familyNames:
          - Killingback
        type: Person
      - givenNames:
          - J
        familyNames:
          - Bieri
        type: Person
      - givenNames:
          - T
        familyNames:
          - Flatt
        type: Person
    title: >-
      Evolution in group-structured populations can resolve the tragedy of the
      commons
    type: Article
    datePublished: '2006'
    isPartOf:
      pageStart: 1477
      pageEnd: 1481
      title: 'Proceedings of the Royal Society of London Series B: Biological Sciences'
      volumeNumber: 273
      type: PublicationVolume
    id: pone.0093988-Killingback3
  - authors:
      - givenNames:
          - C
        familyNames:
          - Holt
        type: Person
      - givenNames:
          - A
        familyNames:
          - Roth
        type: Person
    title: 'The Nash equilibrium: A perspective'
    type: Article
    datePublished: '2004'
    isPartOf:
      pageStart: 3999
      pageEnd: 4002
      title: Proceedings of the National Academy of Sciences
      volumeNumber: 101
      type: PublicationVolume
    id: pone.0093988-Holt1
  - authors:
      - givenNames:
          - K
        familyNames:
          - Basu
        type: Person
    title: "The traveler's dilemma: Paradoxes of rationality in game theory"
    type: Article
    datePublished: '1994'
    isPartOf:
      pageStart: 391
      pageEnd: 395
      title: The American Economic Review
      volumeNumber: 84
      type: PublicationVolume
    id: pone.0093988-Basu1
  - authors:
      - givenNames:
          - K
        familyNames:
          - Basu
        type: Person
    title: The traveler's dilemma
    type: Article
    datePublished: '2007'
    isPartOf:
      pageStart: 90
      pageEnd: 95
      title: Scientific American Magazine
      volumeNumber: 296
      type: PublicationVolume
    id: pone.0093988-Basu2
  - authors:
      - givenNames:
          - J
        familyNames:
          - Goeree
        type: Person
      - givenNames:
          - C
        familyNames:
          - Holt
        type: Person
    title: Ten little treasures of game theory and ten intuitive contradictions
    type: Article
    datePublished: '2001'
    isPartOf:
      pageStart: 1402
      pageEnd: 1422
      title: The American Economic Review
      volumeNumber: 91
      type: PublicationVolume
    id: pone.0093988-Goeree1
  - authors:
      - givenNames:
          - J
        familyNames:
          - Van
          - Huyck
        type: Person
      - givenNames:
          - R
        familyNames:
          - Battalio
        type: Person
      - givenNames:
          - R
        familyNames:
          - Beil
        type: Person
    title: 'Tacit coordination games, strategic uncertainty, and coordination failure'
    type: Article
    datePublished: '1990'
    isPartOf:
      pageStart: 234
      pageEnd: 248
      title: The American Economic Review
      volumeNumber: 80
      type: PublicationVolume
    id: pone.0093988-VanHuyck1
  - authors:
      - givenNames:
          - C
        familyNames:
          - Capra
        type: Person
      - givenNames:
          - J
        familyNames:
          - Goeree
        type: Person
      - givenNames:
          - R
        familyNames:
          - Gomez
        type: Person
      - givenNames:
          - C
        familyNames:
          - Holt
        type: Person
    title: Anomalous behavior in a traveler's dilemma?
    type: Article
    datePublished: '1999'
    isPartOf:
      pageStart: 678
      pageEnd: 690
      title: The American Economic Review
      volumeNumber: 89
      type: PublicationVolume
    id: pone.0093988-Capra1
  - authors:
      - givenNames:
          - J
        familyNames:
          - Goeree
        type: Person
      - givenNames:
          - C
        familyNames:
          - Holt
        type: Person
    title: 'Stochastic game theory: For playing games, not just for doing theory'
    type: Article
    datePublished: '1999'
    isPartOf:
      pageStart: 10564
      pageEnd: 10567
      title: Proceedings of the National Academy of Sciences
      volumeNumber: 96
      type: PublicationVolume
    id: pone.0093988-Goeree2
  - authors: []
    title: ''
    type: Article
    id: pone.0093988-Becker1
  - authors:
      - givenNames:
          - K
        familyNames:
          - Basu
        type: Person
      - givenNames:
          - L
        familyNames:
          - Becchetti
        type: Person
      - givenNames:
          - L
        familyNames:
          - Stanca
        type: Person
    title: >-
      Experiments with the Travelers Dilemma: welfare, strategic choice and
      implicit collusion
    type: Article
    datePublished: '2011'
    isPartOf:
      pageStart: 575
      pageEnd: 595
      title: Social Choice and Welfare
      volumeNumber: 37
      type: PublicationVolume
    id: pone.0093988-Basu3
  - authors: []
    title: ''
    type: Article
    id: pone.0093988-Hofbauer1
  - authors:
      - givenNames:
          - M
        familyNames:
          - Manapat
        type: Person
      - givenNames:
          - D
        familyNames:
          - Rand
        type: Person
      - givenNames:
          - C
        familyNames:
          - Pawlowitsch
        type: Person
      - givenNames:
          - M
        familyNames:
          - Nowak
        type: Person
    title: Stochastic evolutionary dynamics resolve the Traveler's Dilemma
    type: Article
    datePublished: '2012'
    isPartOf:
      pageStart: 119
      pageEnd: 127
      title: Journal of Theoretical Biology
      volumeNumber: 303
      type: PublicationVolume
    id: pone.0093988-Manapat1
  - authors:
      - givenNames:
          - C
        familyNames:
          - Riehl
        type: Person
    title: >-
      Living with strangers: direct benefits favour non-kin cooperation in a
      communally nesting bird
    type: Article
    datePublished: '2011'
    isPartOf:
      pageStart: 1728
      pageEnd: 1735
      title: 'Proceedings of the Royal Society B: Biological Sciences'
      volumeNumber: 278
      type: PublicationVolume
    id: pone.0093988-Riehl1
  - authors:
      - givenNames:
          - C
        familyNames:
          - Riehl
        type: Person
      - givenNames:
          - L
        familyNames:
          - Jara
        type: Person
    title: >-
      Natural history and reproductive biology of the communally breeding
      Greater (Ani Crotophaga) major at Gatún Lake, Panama
    type: Article
    datePublished: '2009'
    isPartOf:
      pageStart: 679
      pageEnd: 687
      title: The Wilson Journal of Ornithology
      volumeNumber: 121
      type: PublicationVolume
    id: pone.0093988-Riehl2
  - authors:
      - givenNames:
          - J
        familyNames:
          - Bryant
        type: Person
    title: A simple rational expectations Keynes-type model
    type: Article
    datePublished: '1983'
    isPartOf:
      pageStart: 525
      pageEnd: 528
      title: The Quarterly Journal of Economics
      volumeNumber: 98
      type: PublicationVolume
    id: pone.0093988-Bryant1
  - authors:
      - givenNames:
          - S
        familyNames:
          - Anderson
        type: Person
      - givenNames:
          - J
        familyNames:
          - Goeree
        type: Person
      - givenNames:
          - C
        familyNames:
          - Holt
        type: Person
    title: >-
      Minimum-effort coordination games: Stochastic potential and logit
      equilibrium
    type: Article
    datePublished: '2001'
    isPartOf:
      pageStart: 177
      pageEnd: 199
      title: Games and Economic Behavior
      volumeNumber: 34
      type: PublicationVolume
    id: pone.0093988-Anderson1
  - authors:
      - givenNames:
          - J
        familyNames:
          - Halpern
        type: Person
      - givenNames:
          - R
        familyNames:
          - Pass
        type: Person
    title: 'Iterated regret minimization: A new solution concept'
    type: Article
    datePublished: '2012'
    isPartOf:
      pageStart: 184
      pageEnd: 207
      title: Games and Economic Behavior
      volumeNumber: 74
      type: PublicationVolume
    id: pone.0093988-Halpern1
  - authors:
      - givenNames:
          - V
        familyNames:
          - Capraro
        type: Person
    title: A model of human cooperation in social dilemmas
    type: Article
    datePublished: '2013'
    isPartOf:
      pageStart: 72427
      title: PLoS ONE
      volumeNumber: 8
      type: PublicationVolume
    id: pone.0093988-Capraro1
  - authors:
      - givenNames:
          - V
        familyNames:
          - Capraro
        type: Person
      - givenNames:
          - M
        familyNames:
          - Venanzi
        type: Person
      - givenNames:
          - M
        familyNames:
          - Polukarov
        type: Person
      - givenNames:
          - 'N'
        familyNames:
          - Jennings
        type: Person
    title: Cooperative equilibria in iterated social dilemmas
    type: Article
    datePublished: '2013'
    isPartOf:
      pageStart: 146
      pageEnd: 158
      title: >-
        Proceedings of the 6th International Symposium in Algorithmic Game
        Theory
      volumeNumber: 8146
      type: PublicationVolume
    id: pone.0093988-Capraro2
  - authors:
      - givenNames:
          - R
        familyNames:
          - Li
        type: Person
      - givenNames:
          - J
        familyNames:
          - Yu
        type: Person
      - givenNames:
          - J
        familyNames:
          - Lin
        type: Person
    title: Evolution of cooperation in spatial Traveler's Dilemma game
    type: Article
    datePublished: '2013'
    isPartOf:
      pageStart: 58597
      title: PLoS ONE
      volumeNumber: 8
      type: PublicationVolume
    id: pone.0093988-Li1
  - authors:
      - givenNames:
          - C
        familyNames:
          - Camerer
        type: Person
      - givenNames:
          - T
        familyNames:
          - Ho
        type: Person
      - givenNames:
          - J
        familyNames:
          - Chong
        type: Person
    title: A cognitive hierarchy model of games
    type: Article
    datePublished: '2004'
    isPartOf:
      pageStart: 861
      pageEnd: 898
      title: The Quarterly Journal of Economics
      volumeNumber: 119
      type: PublicationVolume
    id: pone.0093988-Camerer1
  - authors:
      - givenNames:
          - M
        familyNames:
          - Costa-Gomes
        type: Person
      - givenNames:
          - V
        familyNames:
          - Crawford
        type: Person
      - givenNames:
          - B
        familyNames:
          - Broseta
        type: Person
    title: 'Cognition and Behavior in Normal-Form Games: An Experimental Study'
    type: Article
    datePublished: '2001'
    isPartOf:
      pageStart: 1193
      pageEnd: 1235
      title: Econometrica
      volumeNumber: 69
      type: PublicationVolume
    id: pone.0093988-CostaGomes1
  - authors:
      - givenNames:
          - R
        familyNames:
          - McKelvey
        type: Person
      - givenNames:
          - T
        familyNames:
          - Palfrey
        type: Person
    title: Quantal response equilibria for normal form games
    type: Article
    datePublished: '1995'
    isPartOf:
      pageStart: 6
      pageEnd: 38
      title: Games and Economic Behavior
      volumeNumber: 10
      type: PublicationVolume
    id: pone.0093988-McKelvey1
  - authors:
      - givenNames:
          - D
        familyNames:
          - Stahl
        type: Person
      - givenNames:
          - P
        familyNames:
          - Wilson
        type: Person
    title: Experimental evidence on players' models of other players
    type: Article
    datePublished: '1994'
    isPartOf:
      pageStart: 309
      pageEnd: 327
      title: Journal of Economic Behavior and Organization
      volumeNumber: 25
      type: PublicationVolume
    id: pone.0093988-Stahl1
  - authors: []
    title: ''
    type: Article
    id: pone.0093988-Wright1
  - authors: []
    title: ''
    type: Article
    id: pone.0093988-Tirole1
  - authors:
      - givenNames:
          - J
        familyNames:
          - Metz
        type: Person
      - givenNames:
          - S
        familyNames:
          - Geritz
        type: Person
      - givenNames:
          - G
        familyNames:
          - Meszéna
        type: Person
      - givenNames:
          - F
        familyNames:
          - Jacobs
        type: Person
      - givenNames:
          - J
        familyNames:
          - Van
          - Heerwaarden
        type: Person
    title: >-
      Adaptive dynamics, a geometrical study of the consequences of nearly
      faithful reproduction
    type: Article
    datePublished: '1996'
    isPartOf:
      pageStart: 183
      pageEnd: 231
      title: Stochastic and Spatial Structures of Dynamical Systems
      volumeNumber: 45
      type: PublicationVolume
    id: pone.0093988-Metz1
  - authors:
      - givenNames:
          - S
        familyNames:
          - Geritz
        type: Person
      - givenNames:
          - J
        familyNames:
          - Metz
        type: Person
      - givenNames:
          - É
        familyNames:
          - Kisdi
        type: Person
      - givenNames:
          - G
        familyNames:
          - Meszéna
        type: Person
    title: Dynamics of adaptation and evolutionary branching
    type: Article
    datePublished: '1997'
    isPartOf:
      pageStart: 2024
      pageEnd: 2027
      title: Physical Review Letters
      volumeNumber: 78
      type: PublicationVolume
    id: pone.0093988-Geritz1
  - authors:
      - givenNames:
          - S
        familyNames:
          - Geritz
        type: Person
      - givenNames:
          - G
        familyNames:
          - Meszéna
        type: Person
      - givenNames:
          - J
        familyNames:
          - Metz
        type: Person
    title: >-
      Evolutionarily singular strategies and the adaptive growth and branching
      of the evolutionary tree
    type: Article
    datePublished: '1997'
    isPartOf:
      pageStart: 35
      pageEnd: 57
      title: Evolutionary Ecology
      volumeNumber: 12
      type: PublicationVolume
    id: pone.0093988-Geritz2
  - authors:
      - givenNames:
          - M
        familyNames:
          - Nowak
        type: Person
      - givenNames:
          - R
        familyNames:
          - May
        type: Person
    title: Evolutionary games and spatial chaos
    type: Article
    datePublished: '1992'
    isPartOf:
      pageStart: 826
      pageEnd: 829
      title: Nature
      volumeNumber: 359
      type: PublicationVolume
    id: pone.0093988-Nowak1
  - authors:
      - givenNames:
          - T
        familyNames:
          - Killingback
        type: Person
      - givenNames:
          - M
        familyNames:
          - Doebeli
        type: Person
    title: 'Spatial evolutionary game theory: Hawks and Doves revisited'
    type: Article
    datePublished: '1996'
    isPartOf:
      pageStart: 1135
      pageEnd: 1144
      title: 'Proceedings of the Royal Society of London Series B: Biological Sciences'
      volumeNumber: 263
      type: PublicationVolume
    id: pone.0093988-Killingback4
  - authors:
      - givenNames:
          - M
        familyNames:
          - Nakamaru
        type: Person
      - givenNames:
          - H
        familyNames:
          - Matsuda
        type: Person
      - givenNames:
          - 'Y'
        familyNames:
          - Iwasa
        type: Person
    title: The evolution of cooperation in a lattice-structured population
    type: Article
    datePublished: '1997'
    isPartOf:
      pageStart: 65
      pageEnd: 81
      title: Journal of Theoretical Biology
      volumeNumber: 184
      type: PublicationVolume
    id: pone.0093988-Nakamaru1
  - authors:
      - givenNames:
          - M
        familyNames:
          - Van
          - Baalen
        type: Person
      - givenNames:
          - D
        familyNames:
          - Rand
        type: Person
    title: The unit of selection in viscous populations and the evolution of altruism
    type: Article
    datePublished: '1998'
    isPartOf:
      pageStart: 631
      pageEnd: 648
      title: Journal of Theoretical Biology
      volumeNumber: 193
      type: PublicationVolume
    id: pone.0093988-VanBaalen1
  - authors:
      - givenNames:
          - M
        familyNames:
          - Ifti
        type: Person
      - givenNames:
          - T
        familyNames:
          - Killingback
        type: Person
      - givenNames:
          - M
        familyNames:
          - Doebeli
        type: Person
    title: >-
      Effects of neighbourhood size and connectivity on spatial Continuous
      Prisoner's Dilemma
    type: Article
    datePublished: '2004'
    isPartOf:
      pageStart: 97
      pageEnd: 106
      title: Journal of Theoretical Biology
      volumeNumber: 231
      type: PublicationVolume
    id: pone.0093988-Ifti1
  - authors:
      - givenNames:
          - C
        familyNames:
          - Hauert
        type: Person
      - givenNames:
          - M
        familyNames:
          - Doebeli
        type: Person
    title: >-
      Spatial structure often inhibits the evolution of cooperation in the
      snowdrift game
    type: Article
    datePublished: '2004'
    isPartOf:
      pageStart: 643
      pageEnd: 646
      title: Nature
      volumeNumber: 428
      type: PublicationVolume
    id: pone.0093988-Hauert1
  - authors:
      - givenNames:
          - F
        familyNames:
          - Santos
        type: Person
      - givenNames:
          - J
        familyNames:
          - Pacheco
        type: Person
    title: >-
      Scale-free networks provide a unifying framework for the emergence of
      cooperation
    type: Article
    datePublished: '2005'
    isPartOf:
      pageStart: 98
      pageEnd: 104
      title: Physical Review Letters
      volumeNumber: 95
      type: PublicationVolume
    id: pone.0093988-Santos1
  - authors:
      - givenNames:
          - H
        familyNames:
          - Ohtsuki
        type: Person
      - givenNames:
          - C
        familyNames:
          - Hauert
        type: Person
      - givenNames:
          - E
        familyNames:
          - Lieberman
        type: Person
      - givenNames:
          - M
        familyNames:
          - Nowak
        type: Person
    title: >-
      A simple rule for the evolution of cooperation on graphs and social
      networks
    type: Article
    datePublished: '2006'
    isPartOf:
      pageStart: 502
      pageEnd: 505
      title: Nature
      volumeNumber: 441
      type: PublicationVolume
    id: pone.0093988-Ohtsuki1
  - authors:
      - givenNames:
          - G
        familyNames:
          - Szabo
        type: Person
      - givenNames:
          - G
        familyNames:
          - Fáth
        type: Person
    title: Evolutionary games on graphs
    type: Article
    datePublished: '2007'
    isPartOf:
      pageStart: 97
      pageEnd: 216
      title: Physics Reports
      volumeNumber: 446
      type: PublicationVolume
    id: pone.0093988-Szabo1
  - authors:
      - givenNames:
          - D
        familyNames:
          - Watts
        type: Person
      - givenNames:
          - S
        familyNames:
          - Strogatz
        type: Person
    title: Collective dynamics of ‘small-world’ networks
    type: Article
    datePublished: '1998'
    isPartOf:
      pageStart: 440
      pageEnd: 442
      title: Nature
      volumeNumber: 393
      type: PublicationVolume
    id: pone.0093988-Watts1
  - authors:
      - givenNames:
          - A
        familyNames:
          - Barabási
        type: Person
      - givenNames:
          - R
        familyNames:
          - Albert
        type: Person
    title: Emergence of scaling in random networks
    type: Article
    datePublished: '1999'
    isPartOf:
      pageStart: 509
      pageEnd: 512
      title: Science
      volumeNumber: 286
      type: PublicationVolume
    id: pone.0093988-Barabsi1
  - authors:
      - givenNames:
          - R
        familyNames:
          - Albert
        type: Person
      - givenNames:
          - A
        familyNames:
          - Barabási
        type: Person
    title: Statistical mechanics of complex networks
    type: Article
    datePublished: '2002'
    isPartOf:
      pageStart: 47
      pageEnd: 97
      title: Reviews of Modern Physics
      volumeNumber: 74
      type: PublicationVolume
    id: pone.0093988-Albert1
  - authors: []
    title: ''
    type: Article
    id: pone.0093988-Newman1
  - authors:
      - givenNames:
          - M
        familyNames:
          - Dufwenberg
        type: Person
      - givenNames:
          - U
        familyNames:
          - Gneezy
        type: Person
    title: 'Price competition and market concentration: an experimental study'
    type: Article
    datePublished: '2000'
    isPartOf:
      pageStart: 7
      pageEnd: 22
      title: International Journal of Industrial Organization
      volumeNumber: 18
      type: PublicationVolume
    id: pone.0093988-Dufwenberg1
